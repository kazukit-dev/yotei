# Yotei Testing Guidelines

This document outlines the testing strategy and guidelines for the Yotei project.

## Overview

The Yotei project follows a pragmatic testing approach that focuses on business logic and domain objects while minimizing infrastructure testing overhead. We prioritize testing components that directly implement business rules and validation logic.

## File Naming and Structure Conventions

### Test File Naming

- **Required Pattern**: `*.spec.ts` only
- **Prohibited**: `.test.ts` extension is forbidden
- **Examples**:
  - ✅ `calendar.spec.ts`
  - ✅ `create-event.spec.ts`
  - ❌ `calendar.test.ts`
  - ❌ `create-event.test.ts`

### Test File Colocation

- **Principle**: Test files must be colocated with their source files
- **Location**: Place test files in the same directory as the code they test
- **Structure**:
  ```
  modules/calendar/objects/write/
  ├── calendar.ts          # Source file
  ├── calendar.spec.ts     # Test file (colocated)
  ├── name.ts             # Source file
  └── name.spec.ts        # Test file (colocated)
  ```
- **Benefits**:
  - Easy to find related tests
  - Enforces test coverage awareness
  - Simplifies import paths

## Testing Strategy

### Mandatory Test Execution

**CRITICAL**: After writing or modifying any tests, you MUST execute the following command to validate your changes:

```bash
pnpm run test:api
```

This command ensures that:

- All tests pass with the current implementation
- Test syntax and imports are correct
- No regressions have been introduced
- Test coverage requirements are met

**Failure to run this command after test modifications is a violation of testing guidelines.**

### Test Priority Layers

| Layer                              | Test Priority | Rationale                                            |
| ---------------------------------- | ------------- | ---------------------------------------------------- |
| Domain Objects (`objects/`)        | **High**      | Contains core business rules and validation logic    |
| Workflows (`workflows/`)           | **High**      | Orchestrates business processes and application flow |
| API Layer (`api/`)                 | **Skip**      | Thin wrappers around workflows                       |
| Query Services (`query-services/`) | **Skip**      | Primarily data access with minimal logic             |
| Repositories (`repositories/`)     | **Skip**      | Thin data access layer                               |

### What to Test

#### 1. Domain Objects (Value Objects and Entities)

- **Priority**: High
- **Rationale**: Contains critical business rules and validation logic
- **Scope**: All validation functions, business rule enforcement, and domain logic

**Example layers to test:**

- `objects/write/` - Value object creation and validation
- `objects/read/` - Data transformation and business rules

#### 2. Workflows (Business Logic)

- **Priority**: High
- **Rationale**: Core business processes that directly impact user functionality
- **Scope**: End-to-end workflow logic, error handling, and business rule orchestration

**Example layers to test:**

- `workflows/` - Business logic coordination and validation

### What NOT to Test

#### 1. API Layer

- **Rationale**: HTTP routes and handlers are primarily thin wrappers around workflows
- **Alternative**: Integration and end-to-end tests cover API functionality

#### 2. Query Services

- **Rationale**: Primarily data access layer with minimal business logic
- **Alternative**: Integration tests and end-to-end tests cover these scenarios

#### 3. Repositories

- **Rationale**: Thin data access layer that primarily wraps ORM operations
- **Alternative**: Database integration tests provide better coverage

#### 4. Database Schema and Migrations

- **Rationale**: Covered by database integration tests and production monitoring
- **Alternative**: Manual testing during development and staging deployment

## Quick Reference Summary

### Test Strategy Overview

- **Focus on business logic**: Test domain objects and workflows primarily
- **Skip infrastructure layers**: query-services and repositories don't need unit tests
- **Use integration tests**: For data layer and end-to-end scenarios

### Test File Conventions Summary

- **File naming**: Use `*.spec.ts` pattern only (`.test.ts` is prohibited)
- **File location**: Colocate test files with source files in the same directory
- **Examples**:
  - ✅ `calendar.spec.ts` (in same directory as `calendar.ts`)
  - ❌ `calendar.test.ts` or separate test directories

## Testing Patterns and Examples

### Domain Object Testing

Test domain objects for valid input handling, invalid input rejection, and proper error messages.

```typescript
// Generated by Copilot
import { describe, expect, test } from "vitest";
import { createCalendarName } from "./name";

describe("createCalendarName", () => {
  test("should create valid calendar name", () => {
    const result = createCalendarName("My Calendar");

    // Alternative using Neverthrow's unsafe methods:
    // expect(result._unsafeUnwrap()).toBe("My Calendar");

    expect(result.isOk()).toBe(true);
    if (result.isOk()) {
      expect(result.value).toBe("My Calendar");
    }
  });

  test("should reject invalid input", () => {
    const result = createCalendarName("");

    // Alternative using Neverthrow's unsafe methods:
    // expect(result._unsafeUnwrapErr()).toBe("Invalid calendar name length");

    expect(result.isErr()).toBe(true);
    if (result.isErr()) {
      expect(result.error).toBe("Invalid calendar name length");
    }
  });
});
```

### Workflow Testing

Test workflows for proper business logic orchestration, validation, and error handling.

```typescript
// Generated by Copilot
import { describe, expect, test } from "vitest";
import {
  createCalendarWorkflow,
  toUnvalidatedCalendar,
} from "./create-calendar";

describe("createCalendarWorkflow", () => {
  test("should process valid calendar creation", () => {
    const input = toUnvalidatedCalendar({
      name: "Test Calendar",
      ownerId: "user-123",
    });

    const result = createCalendarWorkflow()(input);

    expect(result.isOk()).toBe(true);
    if (result.isOk()) {
      expect(result.value.kind).toBe("created");
      expect(result.value.name).toBe("Test Calendar");
    }
  });

  test("should handle validation errors", () => {
    const input = toUnvalidatedCalendar({
      name: "",
      ownerId: "user-123",
    });

    const result = createCalendarWorkflow()(input);

    expect(result.isErr()).toBe(true);
  });
});
```

## Testing Workflow and Commands

### Development Testing Workflow

1. **Write Tests First**: Consider writing tests before implementation (TDD)
2. **Focus on Core Logic**: Prioritize testing domain objects and workflows
3. **Skip Infrastructure**: Don't test API endpoints, repositories, or query services
4. **Test After Changes**: Always run tests after modifying code
5. **Verify Before Commit**: Run complete test suite before committing code

### Available Test Commands

All commands should be executed from the project root directory:

```bash
# During development
pnpm --filter ./apps/api test:watch    # Run tests in watch mode

# Before commit (mandatory)
pnpm run test:api                      # Run all API tests
pnpm run check:api                     # Run API code quality checks

# Complete verification
pnpm test:all                          # Run all tests across workspace

# Testing specific apps
pnpm --filter ./apps/api test          # Test API only
pnpm --filter ./apps/web test          # Test web app only
```

### API Development Test Commands

- **For API development**: `pnpm run test:api` (unit tests) and `pnpm run check:api` (quality checks)
- **Mandatory for API changes**: Run both commands after making API changes
- Run all tests: `pnpm test:all`
- Run API tests: `pnpm --filter ./apps/api test`
- Run tests in watch mode: `pnpm --filter ./apps/api test:watch`

## File Organization

### Standard Directory Structure with Test Coverage

```
modules/
├── calendar/
│   ├── api/                         # ❌ No tests needed
│   │   ├── router.ts
│   │   └── schema.ts
│   ├── objects/                     # ✅ Test thoroughly
│   │   └── write/
│   │       ├── name.ts
│   │       ├── name.spec.ts
│   │       ├── calendar.ts
│   │       └── calendar.spec.ts
│   ├── workflows/                   # ✅ Test thoroughly
│   │   ├── create-calendar.ts
│   │   └── create-calendar.spec.ts
│   ├── query-services/              # ❌ No tests needed
│   │   └── get-calendars.ts
│   └── repositories/                # ❌ No tests needed
│       └── save-calendar.ts
```

### File Naming Convention

All test files must follow these naming patterns:

- Use **`.spec.ts`** extension (required)
- Place next to the file being tested
- Follow the same naming pattern as the source file
- Never use `.test.ts` extension

## Testing Techniques

### Result Type Testing with neverthrow

When testing code that returns `Result` types from the neverthrow library, you can use two approaches:

#### 1. Safe Approach (Conditional Assertions)

```typescript
// Generated by Copilot
test("using safe conditional assertions", () => {
  const result = createCalendar({ name: "My Calendar", ownerId: "user-123" });

  expect(result.isOk()).toBe(true);
  if (result.isOk()) {
    expect(result.value.name).toBe("My Calendar");
  }
});
```

#### 2. Concise Approach (Unsafe Methods)

Use neverthrow's unsafe methods for cleaner test assertions:

```typescript
// Generated by Copilot
test("using unsafe methods for cleaner assertions", () => {
  const result = createCalendar({ name: "My Calendar", ownerId: "user-123" });

  const calendar = result._unsafeUnwrap();
  expect(calendar.name).toBe("My Calendar");
});
```

Important notes about unsafe methods:

- `_unsafeUnwrap()`: Extracts the success value from `Ok` results
- `_unsafeUnwrapErr()`: Extracts the error value from `Err` results
- **Only use these methods in test environments**

### Error Testing Patterns

#### ValidationError Testing

```typescript
// Generated by Copilot
test("should handle validation errors correctly", () => {
  const result = createCalendar({ id: "", name: "", owner_id: "" });

  expect(result.isErr()).toBe(true);
  if (result.isErr()) {
    expect(result.error.message).toBe("Validation Error");
    expect(result.error.errors).toContain("Invalid calendar name length");
  }

  // Alternative using unsafe method:
  // const error = result._unsafeUnwrapErr();
  // expect(error.message).toBe("Validation Error");
  // expect(error.errors).toContain("Invalid calendar name length");
});
```

#### Never Throw Pattern

```typescript
// Generated by Copilot
test("should never throw exceptions", () => {
  expect(() => {
    createCalendarName("");
  }).not.toThrow();
});
```

## Vitest Best Practices

### Property and Object Testing

```typescript
// Generated by Copilot
test("demonstration of object testing methods", () => {
  const calendar = createCalendar(validInput)._unsafeUnwrap();

  // Test specific properties
  expect(calendar).toHaveProperty("id");
  expect(calendar).toHaveProperty("name", "My Calendar");

  // Test entire object structure partially
  expect(calendar).toMatchObject({
    name: "My Calendar",
    ownerId: "user-123",
  });

  // Test array length
  const errors = someFunction()._unsafeUnwrapErr().errors;
  expect(errors).toHaveLength(2);
});
```

### Boolean Assertion Guidelines

**REQUIRED**: Use semantic boolean matchers instead of strict equality:

```typescript
// Generated by Copilot
// ❌ Wrong: Strict boolean comparison
expect(result.isOk()).toBe(true);
expect(result.isErr()).toBe(false);

// ✅ Correct: Semantic boolean matchers
expect(result.isOk()).toBeTruthy();
expect(result.isErr()).toBeFalsy();

// ✅ Also correct for explicit null/undefined checks
expect(value).toBeTruthy(); // Instead of toBe(true)
expect(value).toBeFalsy(); // Instead of toBe(false)
```

**Rationale**:

- `toBeTruthy()` and `toBeFalsy()` are more expressive and flexible
- They handle edge cases like `0`, `""`, `null`, `undefined` correctly
- They align with JavaScript's truthiness semantics

### Async Function Testing

```typescript
// Generated by Copilot
test("should handle async operations", async () => {
  // Verify the exact number of assertions that will run
  expect.assertions(2);

  const result = await someAsyncFunction();

  expect(result.isOk()).toBeTruthy();
  expect(result._unsafeUnwrap()).toBeDefined();
});
```

## Code Verification Process

### Test-Driven Verification Methodology

When implementing or modifying code, follow this systematic verification process:

#### 1. Code Verification Through Testing

**Principle**: All code verification must be done through test code, not manual testing or console output.

```typescript
// Generated by Copilot
// ❌ Wrong: Manual verification
console.log(createEmail("test@example.com")); // Don't do this

// ✅ Correct: Test-driven verification
test("should verify email creation", () => {
  const result = createEmail("test@example.com");
  expect(result.isOk()).toBe(true);
});
```

#### 2. Iterative Verification Cycle

Follow this cycle for all code changes:

1. **Write Verification Test** → 2. **Run Test** → 3. **Fix Code** → 4. **Repeat**

```bash
# Example verification cycle
pnpm --filter ./apps/api test src/path/to/component.spec.ts  # Step 2: Run test
# Step 3: Fix code based on test results
# Step 4: Repeat until all tests pass
```

#### 3. Edge Case Consultation

When encountering edge cases during verification:

- **Identify**: Document the edge case scenario
- **Consult**: Ask for guidance before implementing
- **Document**: Record the decision in test comments

```typescript
// Generated by Copilot
test("should handle edge case: single character email domain", () => {
  // Edge case identified: a@b.c format
  // Consultation result: Skip for OIDC provider context
  const result = createEmail("user@domain.co");
  expect(result.isOk()).toBe(true);
});
```

#### 4. Cleanup After Verification

Once verification is complete:

1. **Delete**: Remove temporary verification/debug code
2. **Finalize**: Write clean, production-ready test code
3. **Validate**: Run full test suite with `pnpm run test:api`

```bash
# Remove temporary files
rm debug-*.js verification-*.ts

# Write final test code
# Run mandatory validation
pnpm run test:api
```

### Verification Best Practices

#### Temporary Test Files

When creating verification tests, use clear naming conventions:

```
debug-email-validation.js     # ❌ Temporary - delete after verification
email.spec.ts                # ✅ Production test - keep and maintain
```

#### Verification Scope

Focus verification on:

- **Critical Logic**: Business rules and validation
- **Edge Cases**: Boundary conditions and special inputs
- **Integration**: How components work together

Skip verification for:

- **Infrastructure**: Database connections, HTTP calls
- **Third-party**: External library behavior
- **Trivial**: Simple getters/setters
